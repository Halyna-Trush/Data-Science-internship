{"cells":[{"cell_type":"markdown","source":["Halyna Trush. Contact Information Phone: +380954200758 Email: frolova.galka@gmail.com LinkedIn: https://www.linkedin.com/in/halyna-trush/"],"metadata":{"id":"8-5FSwNGGiAh"}},{"cell_type":"markdown","source":["This script loads the fine-tuned Mountain NER model and tokenizer from Google Drive\n","and runs an interactive inference session in the console. It supports both\n","`.safetensors` and `.pytorch_model.bin` weight formats and validates required files\n","(`config.json`, `tokenizer.json` or `vocab.txt`). The user can type any sentence,\n","and the script outputs token-level labels and recognized mountain entities."],"metadata":{"id":"dw9vhunGG9Wy"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRhjWDKolTq5","executionInfo":{"status":"ok","timestamp":1762203633409,"user_tz":-120,"elapsed":187141,"user":{"displayName":"Галина Труш","userId":"03124250468350100934"}},"outputId":"4f7cc991-1471-440d-f407-b98847443404"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Model and tokenizer loaded from: /content/drive/MyDrive/mountain_ner_model\n","Device: cpu\n","Mountain NER — interactive mode. Type a sentence or 'exit' to quit.\n","\n","Enter a sentence: From our camp we could clearly see Stormveil Range in the distance.\n","\n","Tokens & Labels:\n","From                 -> O\n","our                  -> O\n","camp                 -> O\n","we                   -> O\n","could                -> O\n","clearly              -> O\n","see                  -> O\n","Stormveil            -> B-MOUNT\n","Range                -> I-MOUNT\n","in                   -> O\n","the                  -> O\n","distance             -> O\n","\n","Entities: ['Stormveil Range']\n","--------------------------------------------------\n","Enter a sentence: The sunrise over Emerald Summit was breathtaking.\n","\n","Tokens & Labels:\n","The                  -> O\n","sunrise              -> O\n","over                 -> O\n","Emerald              -> B-MOUNT\n","Summit               -> I-MOUNT\n","was                  -> O\n","breathtaking         -> O\n","\n","Entities: ['Emerald Summit']\n","--------------------------------------------------\n","Enter a sentence: The sunrise over mount was breathtaking.\n","\n","Tokens & Labels:\n","The                  -> O\n","sunrise              -> O\n","over                 -> O\n","mount                -> O\n","was                  -> O\n","breathtaking         -> O\n","\n","Entities: — none —\n","--------------------------------------------------\n","Enter a sentence: We finally reached the base of Mount Crystal after a two-day trek.\n","\n","Tokens & Labels:\n","We                   -> O\n","finally              -> O\n","reached              -> O\n","the                  -> O\n","base                 -> O\n","of                   -> O\n","Mount                -> B-MOUNT\n","Crystal              -> I-MOUNT\n","after                -> O\n","a                    -> O\n","two                  -> O\n","-                    -> O\n","day                  -> O\n","trek                 -> O\n","\n","Entities: ['Mount Crystal']\n","--------------------------------------------------\n","Enter a sentence: exit\n","Goodbye!\n"]}],"source":["# Load fine-tuned Mountain NER model from Google Drive (handles safetensors or pytorch bin)\n","from google.colab import drive\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","import torch\n","from pathlib import Path\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Path to model on Drive\n","MODEL_DIR = Path(\"/content/drive/MyDrive/mountain_ner_model\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","try:\n","    if not MODEL_DIR.exists():\n","        raise FileNotFoundError(f\"Model directory not found: {MODEL_DIR}\")\n","\n","    # Accept either safetensors or pytorch .bin\n","    has_safetensors = (MODEL_DIR / \"model.safetensors\").exists()\n","    has_ptbin       = (MODEL_DIR / \"pytorch_model.bin\").exists()\n","    if not has_safetensors and not has_ptbin:\n","        raise FileNotFoundError(\"No model weight file found: expected 'model.safetensors' or 'pytorch_model.bin'.\")\n","\n","    # Required config/tokenizer files\n","    required_any = [\n","        (\"config.json\",),  # must exist\n","        (\"tokenizer.json\", \"vocab.txt\"),  # at least one of these must exist\n","    ]\n","    if not (MODEL_DIR / \"config.json\").exists():\n","        raise FileNotFoundError(\"Missing 'config.json' in model directory.\")\n","    if not ((MODEL_DIR / \"tokenizer.json\").exists() or (MODEL_DIR / \"vocab.txt\").exists()):\n","        raise FileNotFoundError(\"Missing tokenizer files: need 'tokenizer.json' or 'vocab.txt'.\")\n","\n","    # Load tokenizer and model (local files only)\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True, local_files_only=True)\n","    model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR, local_files_only=True).to(device).eval()\n","\n","    print(f\"Model and tokenizer loaded from: {MODEL_DIR}\")\n","    print(f\"Device: {device}\")\n","except Exception as e:\n","    print(\"Failed to load model. Please check:\")\n","    print(f\"- Folder exists: {MODEL_DIR}\")\n","    print(\"- Files expected: config.json, tokenizer.json or vocab.txt, and model.safetensors or pytorch_model.bin\")\n","    print(\"Error details:\", e)\n","    model = None\n","    tokenizer = None\n","\n","\n","import re\n","\n","def ner_predict(sentence: str):\n","    \"\"\"\n","    Run inference and return (tokens, labels, entities).\n","    - Regex tokenization to split words and punctuation separately\n","    - Merge consecutive MOUNT tags (B- or I-) into one entity\n","    - Ignore pure punctuation in entity spans\n","    \"\"\"\n","    if model is None or tokenizer is None:\n","        print(\"Model not loaded. Cannot run inference.\")\n","        return [], [], []\n","\n","    # Clean obvious noise at ends (e.g., long dashes)\n","    sentence = re.sub(r\"^\\W+|\\W+$\", \"\", sentence)\n","\n","    # Tokenize into words and punctuation separately (to mimic CoNLL-style)\n","    words = re.findall(r\"\\w+|[^\\w\\s]\", sentence)\n","\n","    # Encode as split-into-words to keep word_ids mapping\n","    enc = tokenizer(\n","        words,\n","        is_split_into_words=True,\n","        return_tensors=\"pt\",\n","        truncation=True\n","    ).to(device)\n","\n","    with torch.inference_mode():\n","        logits = model(**enc).logits\n","\n","    pred_ids = logits.argmax(dim=-1)[0].cpu().tolist()\n","    word_ids = enc.word_ids(0)\n","    id2label = model.config.id2label\n","\n","    tokens, labels, seen = [], [], set()\n","    for pos, wid in enumerate(word_ids):\n","        if wid is None or wid in seen:\n","            continue\n","        seen.add(wid)\n","        tokens.append(words[wid])\n","        labels.append(id2label[pred_ids[pos]])\n","\n","    # Merge logic: treat any consecutive B-MOUNT / I-MOUNT as one entity\n","    ents, cur = [], []\n","    def is_punct(tok: str) -> bool:\n","        return bool(re.fullmatch(r\"[^\\w\\s]\", tok))\n","\n","    for w, lab in zip(tokens, labels):\n","        if lab.endswith(\"MOUNT\"):\n","            # append non-punct tokens only\n","            if not is_punct(w):\n","                cur.append(w)\n","        else:\n","            if cur:\n","                ents.append(\" \".join(cur))\n","                cur = []\n","    if cur:\n","        ents.append(\" \".join(cur))\n","\n","    return tokens, labels, ents\n","\n","\n","# Interactive input\n","if model is not None:\n","    print(\"Mountain NER — interactive mode. Type a sentence or 'exit' to quit.\\n\")\n","    while True:\n","        text = input(\"Enter a sentence: \").strip()\n","        if not text or text.lower() in [\"exit\", \"quit\"]:\n","            print(\"Goodbye!\")\n","            break\n","        tokens, labels, ents = ner_predict(text)\n","        print(\"\\nTokens & Labels:\")\n","        for t, l in zip(tokens, labels):\n","            print(f\"{t:20s} -> {l}\")\n","        print(\"\\nEntities:\", ents if ents else \"— none —\")\n","        print(\"-\" * 50)\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOcHH/PCQjNnF5wKcCFtmf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}